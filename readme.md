Querify: SQL Query Generator for CSV Data ğŸ“ŠğŸ’»
Project Overview ğŸŒŸ
Querify is a web application designed to generate SQL queries based on user-provided CSV data using a local language model (LLM). The application utilizes Streamlit for the user interface, allowing users to upload CSV files and input specific questions to generate SQL queries.

Features âœ¨
CSV Upload: Users can upload CSV files for processing. ğŸ“¤
SQL Query Generation: Based on user input, the app generates SQL queries using the local LLM. ğŸ“
Query Explanation: Users can request explanations for the generated SQL queries. â“
Files ğŸ“‚
app.py
The main application script that leverages Streamlit to create a user interface. It allows users to:

Upload CSV files. ğŸ“
Input questions to generate SQL queries based on the data. ğŸ—¨ï¸
View the generated SQL queries. ğŸ”
Get explanations for the queries. ğŸ“œ
main.py
This script interacts with the LLM via an API endpoint. It handles:

API Interaction: Sends requests to the URL where the LLM is running. ğŸŒ
Prompt Handling: Constructs a prompt to query the benefits of AI models for data analysis and retrieves responses. ğŸ¤–
backend.ipynb
A Jupyter Notebook designed for testing and setting up LLM functionalities. It includes:

Installation instructions for necessary packages like ollama and streamlit. ğŸ“¦
Code for initializing the LLM with the required parameters. âš™ï¸
Functions for reading CSV files, constructing SQL queries, and generating SQL commands like CREATE TABLE and INSERT INTO. ğŸ› ï¸
model.py
Defines the model parameters and instructions for generating SQL queries. It includes:

Model Configuration: Specifies using the llama3 model with a temperature setting of 0 for deterministic outputs. ğŸŒ¡ï¸
System Instructions: Instructs the model to act as a "SQL query master" to generate SQL queries based on natural language questions about CSV data, along with brief explanations. ğŸ“
Libraries Used ğŸ“š
pandas: For data manipulation and processing, especially for reading and handling CSV files. ğŸ“Š
streamlit: For building the web interface to upload CSV files and display SQL queries. ğŸŒ
requests: To make HTTP requests to the LLM API, enabling interaction with the model. ğŸŒ
subprocess: Allows spawning new processes to run the local LLM for SQL query generation. ğŸ”„
sys: Provides system-specific parameters, like encoding and locale settings for proper data handling. âš™ï¸
locale: Configures locale for data formatting (dates, numbers, etc.). ğŸ—“ï¸
json: Used for handling JSON data when sending requests to the LLM API. ğŸ“„
langchain_ollama: For integrating with the Ollama model, which generates SQL queries based on user input. ğŸ”—
Getting Started ğŸš€
Clone the repository:

bash
git clone <repository_url>
cd <repository_folder>
Create a virtual environment (venv):

bash
python -m venv venv
.\venv\Scripts\activate  # On Windows
source venv/bin/activate  # On macOS/Linux
Install required packages:

bash
pip install -r requirements.txt
Run the Streamlit application:

bash
streamlit run app.py
Contributing ğŸ¤
Contributions are welcome! To contribute:

Fork the repository. ğŸ´
Create a new branch for your feature or fix. ğŸŒ±
Submit a pull request with your changes. ğŸ”€
