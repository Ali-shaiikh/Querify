{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama = Ollama (base_url= \"http://localhost:11434\",model=\"sql_gen_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ollama(\"who are you\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#csv file is loaded\n",
    "csv_file_path = './dummycsv/student-dataset.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "#column names and data type is given\n",
    "columns = df.columns\n",
    "data_types = df.dtypes\n",
    "\n",
    "\n",
    "#mapping data types to sql query data types\n",
    "data_type_mapping = {\n",
    "    'int64': 'INT',\n",
    "    'float64': 'FLOAT',\n",
    "    'object': 'TEXT',  # assuming all non-numeric data is text\n",
    "    'datetime64[ns]': 'DATETIME'\n",
    "}\n",
    "\n",
    "#constructing the CREATE TABLE query\n",
    "table_name = ''\n",
    "create_table_query = f\"CREATE TABLE {table_name} (\\n\"\n",
    "for col in columns:\n",
    "    sql_data_type = data_type_mapping[str(data_types[col])]\n",
    "    create_table_query += f\"    {col} {sql_data_type},\\n\"\n",
    "create_table_query = create_table_query.rstrip(',\\n') + \"\\n);\"\n",
    "\n",
    "print(create_table_query)\n",
    "\n",
    "\n",
    "\n",
    "#generate the INSERT INTO statements\n",
    "insert_queries = []\n",
    "for index, row in df.iterrows():\n",
    "    values = ', '.join([f\"'{str(value)}'\" if pd.notnull(value) else 'NULL' for value in row.values])\n",
    "    insert_query = f\"INSERT INTO {table_name} ({', '.join(columns)}) VALUES ({values});\"\n",
    "    insert_queries.append(insert_query)\n",
    "\n",
    "#printing the first few INSERT statements for verification\n",
    "for query in insert_queries[:]:\n",
    "    print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "\n",
    "#csv file is loaded\n",
    "csv_file_path = './dummycsv/student-dataset.csv'  #replacing the csv file...\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "\n",
    "csv_preview = df.head().to_string(index=False)\n",
    "\n",
    "#asking the user to input what query to be generated\n",
    "user_question = input(\"What SQL query do you want based on the CSV data? \").strip()\n",
    "\n",
    "\n",
    "prompt = f\"Here is a sample of the CSV data:\\n\\n{csv_preview}\\n\\nBased on this data, generate a SQL query that answers the following question: {user_question}\"\n",
    "\n",
    "\n",
    "def query_llm(prompt):\n",
    "    try:\n",
    "        #Prepare and run the subprocess to interact with the local LLM\n",
    "        process = subprocess.Popen(\n",
    "            ['ollama', 'run', 'sql_gen_model'],  \n",
    "            stdin=subprocess.PIPE,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True\n",
    "        )\n",
    "        \n",
    "        #prompt is sent to llm\n",
    "        stdout, stderr = process.communicate(prompt)\n",
    "        \n",
    "        if process.returncode == 0:\n",
    "            return stdout.strip()\n",
    "        else:\n",
    "            return f\"Error: {stderr.strip()}\"\n",
    "    except Exception as e:\n",
    "        return f\"An exception occurred: {str(e)}\"\n",
    "\n",
    "#prompt is sent to llm\n",
    "response = query_llm(prompt)\n",
    "\n",
    "#o/p the LLM's generated SQL query\n",
    "print(\"\\nGenerated SQL Query:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "\n",
    "# Function to interact with the local LLM\n",
    "def query_llm(prompt):\n",
    "    try:\n",
    "        # Prepare and run the subprocess to interact with the local LLM\n",
    "        process = subprocess.Popen(\n",
    "            ['ollama', 'run', 'sql_gen_model'],  \n",
    "            stdin=subprocess.PIPE,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True\n",
    "        )\n",
    "        \n",
    "        # Prompt is sent to LLM\n",
    "        stdout, stderr = process.communicate(prompt)\n",
    "        \n",
    "        if process.returncode == 0:\n",
    "            return stdout.strip()\n",
    "        else:\n",
    "            return f\"Error: {stderr.strip()}\"\n",
    "    except Exception as e:\n",
    "        return f\"An exception occurred: {str(e)}\"\n",
    "\n",
    "# Set up the page configuration\n",
    "st.set_page_config(page_title=\"Querify\", layout=\"centered\")\n",
    "\n",
    "# Title\n",
    "st.title(\"Querify\")\n",
    "\n",
    "# CSV file upload\n",
    "uploaded_file = st.file_uploader(\"Upload your CSV file\", type=[\"csv\"])\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(uploaded_file , encoding='utf-8')\n",
    "    st.write(\"Preview of uploaded CSV:\")\n",
    "    st.dataframe(df)\n",
    "\n",
    "    \n",
    "\n",
    "    # Input box for user question\n",
    "    user_question = st.text_input(\"What SQL query do you want based on the CSV data?\", placeholder=\"e.g., Show me all students with a grade higher than 90\")\n",
    "\n",
    "    # Button to generate the SQL query\n",
    "    if st.button(\"Generate SQL Query\"):\n",
    "        # Prepare the prompt for LLM\n",
    "        csv_preview = df.head().to_string(index=False)\n",
    "        prompt = f\"Here is a sample of the CSV data:\\n\\n{csv_preview}\\n\\nBased on this data, generate a SQL query that answers the following question: {user_question}\"\n",
    "        \n",
    "        # Get the response from the LLM\n",
    "        response = query_llm(prompt)\n",
    "        \n",
    "        # Display the generated SQL query\n",
    "        st.markdown(\"### Generated SQL Query:\")\n",
    "        st.code(response)\n",
    "\n",
    "        # Optional: Explain the generated SQL query if needed (this can be another call to LLM)\n",
    "        explanation_prompt = f\"Explain the following SQL query:\\n{response}\"\n",
    "        explanation = query_llm(explanation_prompt)\n",
    "        \n",
    "        # Display the explanation\n",
    "        st.markdown(\"### Explanation of the SQL Query:\")\n",
    "        st.code(explanation)\n",
    "\n",
    "# Footer\n",
    "st.markdown(\"<p style='text-align: center;'>Querify: SQL Query Generator</p>\", unsafe_allow_html=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
